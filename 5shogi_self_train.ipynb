{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5x5 shogiライブラリー設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/han/python-shogi\n",
      "Installing collected packages: python-shogi\n",
      "  Attempting uninstall: python-shogi\n",
      "    Found existing installation: python-shogi 1.0.14\n",
      "    Uninstalling python-shogi-1.0.14:\n",
      "      Successfully uninstalled python-shogi-1.0.14\n",
      "  Running setup.py develop for python-shogi\n",
      "Successfully installed python-shogi-1.0.14\n",
      "Requirement already satisfied: gmpy2 in /Users/han/opt/anaconda3/envs/nhandsome_vscode/lib/python3.7/site-packages (2.0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-cache-dir -e .\n",
    "!pip install gmpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import shogi\n",
    "\n",
    "from shogi.common import *\n",
    "from shogi.features import *\n",
    "from shogi.read_kifu import *\n",
    "from shogi.CSA import *\n",
    "from shogi.player.mcts_player import MctsPlayer\n",
    "from shogi.network.policyvalue_res import PolicyValueResNetwork\n",
    "from shogi import serializers\n",
    "from shogi import cli\n",
    "\n",
    "import gmpy2\n",
    "import random\n",
    "import argparse\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自己対局\n",
    "1. parallel_mcts_players.sh \n",
    "  - 自己対局に使うプレイヤー（**MONTE CARLO TREE SEARCH**)生成\n",
    "2. model_list (**POLICY VALUE NETWORK**)\n",
    "  - 現状を読みどんなコマをどこに動かすか：Policy Network\n",
    "  - 現状かつ確率はどのくらいか：Value Network\n",
    "  - を学習したPre trained Models\n",
    "  - 今の段階ほぼランダム動きで学習されていて、性能は悪いと思われる。\n",
    "3. cli.py\n",
    "  - Player1\n",
    "      - Palrallel Monte Carlo Tree Search : 探索\n",
    "      - model_rand1 : MCTSに使う評価値を推測\n",
    "      - name1\n",
    "  - Player2\n",
    "  - N round \n",
    "      - M games を行い、csa pathにCSAファイルを生成\n",
    "  - CSAファイル（対局のKifu）を集める\n",
    "\n",
    "            '''\n",
    "            N+Player1\n",
    "            N-Player2\n",
    "            PI\n",
    "            +\n",
    "            +3544GI\n",
    "            -1213FU\n",
    "            +5453FU\n",
    "            -1314FU\n",
    "            +2514KA\n",
    "            -3122GI\n",
    "            +5352FU\n",
    "            -2112KI\n",
    "            +4554KI\n",
    "            -1121OU\n",
    "            +5545OU\n",
    "            -4132KA\n",
    "            +5443KI\n",
    "            -3243KA\n",
    "            +4555OU\n",
    "            -0054KI\n",
    "            %TORYO\n",
    "            '''\n",
    "    \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## google colab\n",
    "# !echo -e \"#!/bin/sh\\npython -m shogi.usi.usi_parallel_mcts\" > parallel_mcts_player.sh\n",
    "## local \n",
    "!echo \"#!/bin/sh\\npython -m shogi.usi.usi_parallel_mcts\" > parallel_mcts_player_2.sh\n",
    "!chmod +x parallel_mcts_player_2.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best/best_pv_1 vs base/base_pv start.\n",
      "まで70手で後手の勝ち\n",
      "1 of 5 games finished.\n",
      "best/best_pv_1 vs base/base_pv: 0-1-0 (0.0%)\n",
      "Black vs White: 0-1-0 (0.0%)\n",
      "best/best_pv_1 playing Black: 0-1-0 (0.0%)\n",
      "best/best_pv_1 playing White: 0-0-0 (0.0%)\n",
      "base/base_pv playing Black: 0-0-0 (0.0%)\n",
      "base/base_pv playing White: 1-0-0 (100.0%)\n",
      "base/base_pv vs best/best_pv_1 start.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-91b786530477>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mcsa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data/csa_auto2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mcli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplayer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/python-shogi/shogi/cli.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(engine1, engine2, options1, options2, names, games, resign, mate_win, byoyomi, time, inc, draw, opening, opening_moves, opening_seed, opening_index, keep_process, csa, multi_csa, is_display, debug, print_summary, callback)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;31m# go\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mbestmove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyoyomi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbyoyomi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremain_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBLACK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremain_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWHITE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwinc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwinc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistener\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbestmove\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'check'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python-shogi/shogi/cli.py\u001b[0m in \u001b[0;36mgo\u001b[0;34m(self, ponder, btime, wtime, byoyomi, binc, winc, nodes, listener)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m## TODO HAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "player1 = '/Users/han/python-shogi/parallel_mcts_player_1.sh'\n",
    "player2 = '/Users/han/python-shogi/parallel_mcts_player_2.sh'\n",
    "\n",
    "model_path = '/Users/han/python-shogi/checkpoint'\n",
    "\n",
    "for r in range(5000):\n",
    "    model_list = ['best/bast_pv_2', 'best/best_pv_1','base/base_pv']\n",
    "    \n",
    "    model_rand1 = random.choice(model_list)\n",
    "    model_rand2 = random.choice(model_list)\n",
    "    modelfile1 = model_path+'/'+model_rand1\n",
    "    modelfile2 = model_path+'/'+model_rand2\n",
    "\n",
    "\n",
    "    name1 = model_rand1\n",
    "    name2 = model_rand2\n",
    "\n",
    "    temp_rand1 = random.randint(10,200)\n",
    "    play_rand1 = random.randint(50,200)\n",
    "    temp_rand2 = random.randint(10,200)\n",
    "    play_rand2 = random.randint(50,200)\n",
    "\n",
    "    options1 = {'modelfile':modelfile1,'temperature':temp_rand1,'playout':play_rand1}\n",
    "    options2 = {'modelfile':modelfile2,'temperature':temp_rand2,'playout':play_rand2}\n",
    "\n",
    "    names = [model_rand1, model_rand2]\n",
    "\n",
    "    csa='./data/csa_auto2'\n",
    "\n",
    "    cli.main(player1,player2, options1=options1, options2=options2, names=names, games=5, draw=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_pv\r\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoint/base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Value Network 学習\n",
    "1. CSAファイルの前処理\n",
    "     - 勝負が決まったMatchだけを選ぶ\n",
    "     - Errorを起こした対局除去\n",
    "2. Train / Test list 生成\n",
    "3. Model作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kifu count : 764\n",
      "total kifu num = 764\n",
      "train kifu num = 764\n",
      "test kifu num = 0\n"
     ]
    }
   ],
   "source": [
    "! python utils/filter_csa.py --dir './data/pgn_3'\n",
    "! python utils/make_kifu_list.py './data/pgn_3' './data/kifu_good_6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/09/28 20:43:17\tINFO\tcheckpoint : checkpoint/5_test_210913_1\n",
      "2021/09/28 20:43:17\tINFO\tbatchsize : 32\n",
      "2021/09/28 20:43:17\tINFO\tinitmodel : \n",
      "2021/09/28 20:43:17\tINFO\tresume : \n",
      "2021/09/28 20:43:17\tINFO\tlog : None\n",
      "2021/09/28 20:43:17\tINFO\tlr : 0.01\n"
     ]
    }
   ],
   "source": [
    "# setting\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('kifulist_train', type=str)\n",
    "parser.add_argument('kifulist_test', type=str)\n",
    "parser.add_argument('--batchsize', '-b', type=int, default=32)\n",
    "parser.add_argument('--test_batchsize', type=int, default=512)\n",
    "parser.add_argument('--epoch', '-e', type=int, default=1)\n",
    "parser.add_argument('--model', type=str, default='model/model_test')\n",
    "parser.add_argument('--state', type=str, default='model/state_test')\n",
    "parser.add_argument('--checkpoint', type=str, default='')\n",
    "parser.add_argument('--initmodel', '-m', type=str, default='')\n",
    "parser.add_argument('--resume', '-r', type=str, default='')\n",
    "parser.add_argument('--log', default=None)\n",
    "parser.add_argument('--lr', type=float, default=0.01)\n",
    "parser.add_argument('--eval_interval', '-i', type=int, default=1000)\n",
    "parser.add_argument('--save_interval_epoch', type=int, default=10)\n",
    "\n",
    "args = parser.parse_args(args=['kifu_good_6_train.txt', 'kifu_good_test.txt', '--epoch', '3', '--model', 'model/5_test_210913_1', '--checkpoint', 'checkpoint/5_test_210913_1', '--eval_interval', '2',  '--save_interval_epoch', '5'])\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s\\t%(levelname)s\\t%(message)s', datefmt='%Y/%m/%d %H:%M:%S', filename=args.log, level=logging.DEBUG)\n",
    "logging.info('checkpoint : {}'.format(args.checkpoint))\n",
    "logging.info('batchsize : {}'.format(args.batchsize))\n",
    "logging.info('initmodel : {}'.format(args.initmodel))\n",
    "logging.info('resume : {}'.format(args.resume))\n",
    "logging.info('log : {}'.format(args.log))\n",
    "logging.info('lr : {}'.format(args.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-682aa3cfdeef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPolicyValueResNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_resnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nhandsome_vscode/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nhandsome_vscode/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nhandsome_vscode/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nhandsome_vscode/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nhandsome_vscode/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m             raise RuntimeError(\n\u001b[1;32m    148\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             raise AssertionError(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nhandsome_vscode/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "num_resnet = 4\n",
    "num_channel = 80\n",
    "\n",
    "model=PolicyValueResNetwork(num_resnet, num_channel)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(),lr=args.lr)\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "bce_with_logits_loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習に必要なFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neede functions\n",
    "def mini_batch(positions, i, batchsize):\n",
    "    mini_batch_data = []\n",
    "    mini_batch_move = []\n",
    "    mini_batch_win = []\n",
    "    for b in range(batchsize):\n",
    "        features, move, win = make_features(positions[i + b])\n",
    "        mini_batch_data.append(features)\n",
    "        mini_batch_move.append(move)\n",
    "        mini_batch_win.append(win)\n",
    "\n",
    "    return (torch.from_numpy(np.array(mini_batch_data, dtype=np.float32)).to(device),\n",
    "            torch.from_numpy(np.array(mini_batch_move, dtype=np.long)).to(device),\n",
    "            torch.from_numpy(np.array(mini_batch_win, dtype=np.float32).reshape((-1, 1))).to(device))\n",
    "\n",
    "def mini_batch_for_test(positions, batchsize):\n",
    "    mini_batch_data = []\n",
    "    mini_batch_move = []\n",
    "    mini_batch_win = []\n",
    "    for b in range(batchsize):\n",
    "        features, move, win = make_features(random.choice(positions))\n",
    "        mini_batch_data.append(features)\n",
    "        mini_batch_move.append(move)\n",
    "        mini_batch_win.append(win)\n",
    "\n",
    "    return (torch.from_numpy(np.array(mini_batch_data, dtype=np.float32)).to(device),\n",
    "            torch.from_numpy(np.array(mini_batch_move, dtype=np.long)).to(device),\n",
    "            torch.from_numpy(np.array(mini_batch_win, dtype=np.float32).reshape((-1, 1))).to(device))\n",
    "    \n",
    "def accuracy(y, t):\n",
    "    return (torch.max(y, 1)[1] == t).sum().item() / len(t)\n",
    "\n",
    "def binary_accuracy(y, t):\n",
    "    pred = y >= 0\n",
    "    truth = t >= 0.5\n",
    "    return pred.eq(truth).sum().item() / len(t)\n",
    "\n",
    "def save_checkpoint():        \n",
    "    logging.info('save checkpoint')\n",
    "    path = f'{args.checkpoint}_{epoch}_{t}'\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        't': t,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初期設定（Resume Train / CSAファイルからFeaturesを抽出）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/09/28 20:43:32\tINFO\tread kifu start\n",
      "2021/09/28 20:43:44\tINFO\tload test pickle\n",
      "2021/09/28 20:43:45\tINFO\tsave train pickle\n",
      "2021/09/28 20:43:45\tINFO\tread kifu end\n",
      "2021/09/28 20:43:45\tINFO\ttrain position num = 57063\n",
      "2021/09/28 20:43:45\tINFO\ttest position num = 24\n"
     ]
    }
   ],
   "source": [
    "# Init/Resume\n",
    "if args.initmodel:\n",
    "    logging.info('Load model from {}'.format(args.initmodel))\n",
    "    serializers.load_npz(args.initmodel, model)\n",
    "if args.resume:\n",
    "    checkpoint = torch.load(args.resume, map_location=device)\n",
    "    logging.info(f'Loading the checkpoint from {args.resume}')\n",
    "    epoch = checkpoint['epoch']\n",
    "    t = checkpoint['t']\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "else:\n",
    "    epoch = 0\n",
    "    t = 0\n",
    "    \n",
    "logging.info('read kifu start')\n",
    "\n",
    "# 保存済みのpickleファイルがある場合、pickleファイルを読み込む\n",
    "# train date\n",
    "train_pickle_filename = re.sub(r'\\..*?$', '', args.kifulist_train) + '.pickle'\n",
    "\n",
    "if os.path.exists(train_pickle_filename):\n",
    "    with open(train_pickle_filename, 'rb') as f:\n",
    "        positions_train = pickle.load(f)\n",
    "    logging.info(train_pickle_filename)\n",
    "    logging.info('load train pickle')\n",
    "else:\n",
    "    positions_train = read_kifu(f'./data/{args.kifulist_train}')\n",
    "\n",
    "# test data\n",
    "test_pickle_filename = re.sub(r'\\..*?$', '', args.kifulist_test) + '.pickle'\n",
    "if os.path.exists(test_pickle_filename):\n",
    "    with open(test_pickle_filename, 'rb') as f:\n",
    "        positions_test = pickle.load(f)\n",
    "    logging.info('load test pickle')\n",
    "else:\n",
    "    positions_test = read_kifu(f'./data/{args.kifulist_test}')\n",
    "\n",
    "# 保存済みのpickleがない場合、pickleファイルを保存する\n",
    "if not os.path.exists(train_pickle_filename):\n",
    "    with open('./data/new_new.pickle', 'wb') as f:\n",
    "        pickle.dump(positions_train, f, pickle.HIGHEST_PROTOCOL)\n",
    "    logging.info('save train pickle')\n",
    "if not os.path.exists(test_pickle_filename):\n",
    "    with open(test_pickle_filename, 'wb') as f:\n",
    "        pickle.dump(positions_test, f, pickle.HIGHEST_PROTOCOL)\n",
    "    logging.info('save test pickle')\n",
    "logging.info('read kifu end')\n",
    "\n",
    "logging.info('train position num = {}'.format(len(positions_train)))\n",
    "logging.info('test position num = {}'.format(len(positions_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414509\n"
     ]
    }
   ],
   "source": [
    "with open('./data//kifu_good_4_train.pickle', 'rb') as f:\n",
    "    temp1 = pickle.load(f)\n",
    "with open('./kifu_good_5_train.pickle', 'rb') as f:\n",
    "    temp2 = pickle.load(f)\n",
    "temp = temp1+temp2\n",
    "print(len(temp))\n",
    "with open('./csa_good.pickle', 'wb') as f:\n",
    "        pickle.dump(temp, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mcsa\u001b[m\u001b[m/\r\n",
      "\u001b[34mcsa_auto2\u001b[m\u001b[m/\r\n",
      "\u001b[34mcsa_current\u001b[m\u001b[m/\r\n",
      "kifu_good_5_test.txt\r\n",
      "kifu_good_5_train.txt\r\n",
      "kifu_good_6_test.txt\r\n",
      "kifu_good_6_train.txt\r\n",
      "new_new.pickle\r\n",
      "\u001b[34mpgn\u001b[m\u001b[m/\r\n",
      "\u001b[34mpgn_2\u001b[m\u001b[m/\r\n",
      "\u001b[34mpgn_3\u001b[m\u001b[m/\r\n",
      "\u001b[34mpgns\u001b[m\u001b[m/\r\n",
      "pgnsShokidoki UEC9++TJshogi5x5 0.19.pgn\r\n",
      "\u001b[34mpickle\u001b[m\u001b[m/\r\n",
      "\u001b[34mtemp\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158356"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [1., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 1., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 1., 0.],\n",
       "           [0., 0., 1., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [1., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 1.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[1., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 1., 0., 1., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 1., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0.]]]]), tensor([13]), tensor([[1.]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='cpu'\n",
    "temp2 = mini_batch(temp1[25:27],1,1)\n",
    "temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# train\n",
    "logging.info('start training')\n",
    "\n",
    "itr = 0\n",
    "sum_loss1 = 0\n",
    "sum_loss2 = 0\n",
    "sum_loss = 0\n",
    "\n",
    "for e in range(args.epoch):\n",
    "    epoch += 1\n",
    "    itr_eval = 0\n",
    "    sum_loss1_eval = 0\n",
    "    sum_loss2_eval = 0\n",
    "    sum_loss_eval = 0\n",
    "\n",
    "    positions_train_shuffled = random.sample(positions_train, len(positions_train))\n",
    "  \n",
    "    for i in range(0, len(positions_train_shuffled)-args.batchsize, args.batchsize):\n",
    "        t += 1\n",
    "        itr += 1\n",
    "        itr_eval += 1\n",
    "\n",
    "        x, t1, t2 = mini_batch(positions_train_shuffled, i, args.batchsize)\n",
    "        model.train()\n",
    "        y1, y2 = model(x)\n",
    "\n",
    "        loss1 = cross_entropy_loss(y1, t1)\n",
    "        loss1 = loss1.mean()\n",
    "        loss2 = bce_with_logits_loss(y2, t2)\n",
    "        loss = loss1 + loss2\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sum_loss1_eval += loss1.item()\n",
    "        sum_loss2_eval += loss2.item()\n",
    "        sum_loss_eval += loss.item()\n",
    "\n",
    "        sum_loss1 += loss1.item()\n",
    "        sum_loss2 += loss2.item()\n",
    "        sum_loss += loss.item()\n",
    "\n",
    "        if t % args.eval_interval == 0:\n",
    "            with torch.no_grad():\n",
    "                x, t1, t2 = mini_batch_for_test(positions_test, args.test_batchsize)\n",
    "                y1, y2 = model(x)\n",
    "\n",
    "                loss1 = cross_entropy_loss(y1, t1)\n",
    "                loss1 = loss1.mean()\n",
    "                loss2 = bce_with_logits_loss(y2, t2)\n",
    "                loss = loss1 + loss2\n",
    "\n",
    "                loss, current = loss1.item(), t\n",
    "                # print(f\"loss1: {loss1:>7f}  loss2: {loss2:>7f}  loss: {loss:>7f}  [{current:>5d}]\")\n",
    "                logging.info('epoch = {}, iteration = {}, loss_policy = {}, loss_value = {}, loss = {}, accuracy = {}, {}'.format(\n",
    "                    epoch, t, sum_loss1/itr, sum_loss2/itr, sum_loss/itr ,accuracy(y1,t1), binary_accuracy(y2,t2)))\n",
    "\n",
    "                itr = 0\n",
    "                sum_loss1 = 0\n",
    "                sum_loss2 = 0\n",
    "                sum_loss = 0\n",
    "          \n",
    "    logging.info('validate test set')\n",
    "    itr_test = 0\n",
    "    sum_test_accuracy1 = 0\n",
    "    sum_test_accuracy2 = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(positions_test)-args.batchsize, args.batchsize):\n",
    "            x, t1, t2 = mini_batch_for_test(positions_test, args.batchsize)\n",
    "            y1 = model(x)\n",
    "\n",
    "            itr_test += 1\n",
    "            sum_test_accuracy1 += accuracy(y1, t1)\n",
    "            sum_test_accuracy2 += binary_accuracy(y2, t2)\n",
    "\n",
    "        logging.info('epoch = {}, iteration = {}, loss_polish = {}, loss_value = {}, loss = {}, accuracy = {}, {}'.format(\n",
    "            epoch, t, sum_loss1_eval/itr_eval, sum_loss2_eval/itr_eval, sum_loss_eval/itr_eval, sum_test_accuracy1/itr_test, sum_test_accuracy2/itr_test))\n",
    "\n",
    "        writer.add_scalar('Train_Loss_Policy/Iteration', sum_loss1_eval/itr_eval, t)\n",
    "        writer.add_scalar('Train_Loss_Value/Iteration', sum_loss2_eval/itr_eval, t)\n",
    "        writer.add_scalar('Train_Loss/Iteration', sum_loss_eval/itr_eval, t)\n",
    "\n",
    "        writer.add_scalar('Test_Acc_Policy/Iteration', sum_test_accuracy1/itr_test, t)\n",
    "        writer.add_scalar('Test_Acc_/Iteration', sum_test_accuracy2/itr_test, t)\n",
    "\n",
    "    if e % args.save_interval_epoch == 0:\n",
    "        save_checkpoint()\n",
    "\n",
    "logging.info('End train')\n",
    "save_checkpoint()\n",
    "\n",
    "logging.info('Save model : {}'.format(args.model))\n",
    "serializers.save_npz(args.model, model)\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('nhandsome_vscode': conda)",
   "language": "python",
   "name": "python37464bitnhandsomevscodeconda77d3a77a3efc4a4db975e8cab8804a1b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
