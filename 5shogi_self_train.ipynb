{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5x5 shogiライブラリー設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/han/python-shogi\n",
      "Installing collected packages: python-shogi\n",
      "  Attempting uninstall: python-shogi\n",
      "    Found existing installation: python-shogi 1.0.14\n",
      "    Uninstalling python-shogi-1.0.14:\n",
      "      Successfully uninstalled python-shogi-1.0.14\n",
      "  Running setup.py develop for python-shogi\n",
      "Successfully installed python-shogi-1.0.14\n",
      "Requirement already satisfied: gmpy2 in /Users/han/opt/anaconda3/envs/nhandsome_vscode/lib/python3.7/site-packages (2.0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-cache-dir -e .\n",
    "!pip install gmpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import shogi\n",
    "\n",
    "from shogi.common import *\n",
    "from shogi.features import *\n",
    "from shogi.read_kifu import *\n",
    "from shogi.CSA import *\n",
    "from shogi.player.mcts_player import MctsPlayer\n",
    "from shogi.network.policyvalue_res import PolicyValueResNetwork\n",
    "from shogi import serializers\n",
    "from shogi import cli\n",
    "\n",
    "import gmpy2\n",
    "import random\n",
    "import argparse\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自己対局\n",
    "1. parallel_mcts_players.sh \n",
    "  - 自己対局に使うプレイヤー（**MONTE CARLO TREE SEARCH**)生成\n",
    "2. model_list (**POLICY VALUE NETWORK**)\n",
    "  - 現状を読みどんなコマをどこに動かすか：Policy Network\n",
    "  - 現状かつ確率はどのくらいか：Value Network\n",
    "  - を学習したPre trained Models\n",
    "  - 今の段階ほぼランダム動きで学習されていて、性能は悪いと思われる。\n",
    "3. cli.py\n",
    "  - Player1\n",
    "      - Palrallel Monte Carlo Tree Search : 探索\n",
    "      - model_rand1 : MCTSに使う評価値を推測\n",
    "      - name1\n",
    "  - Player2\n",
    "  - N round \n",
    "      - M games を行い、csa pathにCSAファイルを生成\n",
    "  - CSAファイル（対局のKifu）を集める\n",
    "\n",
    "            '''\n",
    "            N+Player1\n",
    "            N-Player2\n",
    "            PI\n",
    "            +\n",
    "            +3544GI\n",
    "            -1213FU\n",
    "            +5453FU\n",
    "            -1314FU\n",
    "            +2514KA\n",
    "            -3122GI\n",
    "            +5352FU\n",
    "            -2112KI\n",
    "            +4554KI\n",
    "            -1121OU\n",
    "            +5545OU\n",
    "            -4132KA\n",
    "            +5443KI\n",
    "            -3243KA\n",
    "            +4555OU\n",
    "            -0054KI\n",
    "            %TORYO\n",
    "            '''\n",
    "    \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## google colab\n",
    "# !echo -e \"#!/bin/sh\\npython -m shogi.usi.usi_parallel_mcts\" > parallel_mcts_player.sh\n",
    "## local \n",
    "!echo \"#!/bin/sh\\npython -m shogi.usi.usi_parallel_mcts\" > parallel_mcts_player.sh\n",
    "!chmod +x parallel_mcts_player.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_shogi_auto1_172_609052 vs 5_shogi_auto1_132_467412 start.\n",
      "まで35手で後手の反則負け\n",
      "1 of 1 games finished.\n",
      "5_shogi_auto1_172_609052 vs 5_shogi_auto1_132_467412: 0-1-0 (0.0%)\n",
      "Black vs White: 0-1-0 (0.0%)\n",
      "5_shogi_auto1_172_609052 playing Black: 0-1-0 (0.0%)\n",
      "5_shogi_auto1_172_609052 playing White: 0-0-0 (0.0%)\n",
      "5_shogi_auto1_132_467412 playing Black: 0-0-0 (0.0%)\n",
      "5_shogi_auto1_132_467412 playing White: 1-0-0 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "player1 = '/content/drive/MyDrive/fusic/5shogi_nhand/parallel_mcts_player.sh'\n",
    "player2 = '/content/drive/MyDrive/fusic/5shogi_nhand/parallel_mcts_player.sh'\n",
    "\n",
    "model_path = '/content/drive/MyDrive/fusic/5shogi_nhand/checkpoint'\n",
    "\n",
    "model_list = ['5_shogi_auto1_27_95607', '5_shogi_auto1_27_95607']\n",
    "\n",
    "model_rand1 = random.choice(model_list)\n",
    "model_rand2 = random.choice(model_list)\n",
    "modelfile1 = model_path+'/'+model_rand1\n",
    "modelfile2 = model_path+'/'+model_rand2\n",
    "\n",
    "\n",
    "name1 = model_rand1\n",
    "name2 = model_rand2\n",
    "\n",
    "temp_rand1 = random.randint(10,200)\n",
    "play_rand1 = random.randint(50,200)\n",
    "temp_rand2 = random.randint(10,200)\n",
    "play_rand2 = random.randint(50,200)\n",
    "\n",
    "options1 = {'modelfile':modelfile1,'temperature':temp_rand1,'playout':play_rand1}\n",
    "options2 = {'modelfile':modelfile2,'temperature':temp_rand2,'playout':play_rand2}\n",
    "\n",
    "\n",
    "!cd shogi; python cli.py {model_rand1} {model_rand2} {name1} {name2} --games {1} --round {1} --csa './data/csa_auto2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_20210916152133.csa auto_20210916152150.csa\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/csa_auto2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Value Network 学習\n",
    "1. CSAファイルの前処理\n",
    "     - 勝負が決まったMatchだけを選ぶ\n",
    "     - Errorを起こした対局除去\n",
    "2. Train / Test list 生成\n",
    "3. Model作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python utils/filter_csa.py --dir './data/csa_auto2'\n",
    "! python utils/make_kifu_list.py './data/csa_auto2' './data/kifu_auto2_list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('kifulist_train', type=str)\n",
    "parser.add_argument('kifulist_test', type=str)\n",
    "parser.add_argument('--batchsize', '-b', type=int, default=32)\n",
    "parser.add_argument('--test_batchsize', type=int, default=512)\n",
    "parser.add_argument('--epoch', '-e', type=int, default=1)\n",
    "parser.add_argument('--model', type=str, default='model/model_test')\n",
    "parser.add_argument('--state', type=str, default='model/state_test')\n",
    "parser.add_argument('--checkpoint', type=str, default='')\n",
    "parser.add_argument('--initmodel', '-m', type=str, default='')\n",
    "parser.add_argument('--resume', '-r', type=str, default='')\n",
    "parser.add_argument('--log', default=None)\n",
    "parser.add_argument('--lr', type=float, default=0.01)\n",
    "parser.add_argument('--eval_interval', '-i', type=int, default=1000)\n",
    "parser.add_argument('--save_interval_epoch', type=int, default=10)\n",
    "\n",
    "args = parser.parse_args(args=['kifu_list_train.txt', 'kifu_list_test.txt', '--epoch', '3', '--model', 'model/5_test_210913_1', '--checkpoint', 'checkpoint/5_test_210913_1', '--eval_interval', '2',  '--save_interval_epoch', '5'])\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s\\t%(levelname)s\\t%(message)s', datefmt='%Y/%m/%d %H:%M:%S', filename=args.log, level=logging.DEBUG)\n",
    "logging.info('checkpoint : {}'.format(args.checkpoint))\n",
    "logging.info('batchsize : {}'.format(args.batchsize))\n",
    "logging.info('initmodel : {}'.format(args.initmodel))\n",
    "logging.info('resume : {}'.format(args.resume))\n",
    "logging.info('log : {}'.format(args.log))\n",
    "logging.info('lr : {}'.format(args.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "num_resnet = 3\n",
    "num_channel = 80\n",
    "\n",
    "model=PolicyValueResNetwork(num_resnet, num_channel)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(),lr=args.lr)\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "bce_with_logits_loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習に必要なFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neede functions\n",
    "def mini_batch(positions, i, batchsize):\n",
    "    mini_batch_data = []\n",
    "    mini_batch_move = []\n",
    "    mini_batch_win = []\n",
    "    for b in range(batchsize):\n",
    "        features, move, win = make_features(positions[i + b])\n",
    "        mini_batch_data.append(features)\n",
    "        mini_batch_move.append(move)\n",
    "        mini_batch_win.append(win)\n",
    "\n",
    "    return (torch.from_numpy(np.array(mini_batch_data, dtype=np.float32)).to(device),\n",
    "            torch.from_numpy(np.array(mini_batch_move, dtype=np.long)).to(device),\n",
    "            torch.from_numpy(np.array(mini_batch_win, dtype=np.float32).reshape((-1, 1))).to(device))\n",
    "\n",
    "def mini_batch_for_test(positions, batchsize):\n",
    "    mini_batch_data = []\n",
    "    mini_batch_move = []\n",
    "    mini_batch_win = []\n",
    "    for b in range(batchsize):\n",
    "        features, move, win = make_features(random.choice(positions))\n",
    "        mini_batch_data.append(features)\n",
    "        mini_batch_move.append(move)\n",
    "        mini_batch_win.append(win)\n",
    "\n",
    "    return (torch.from_numpy(np.array(mini_batch_data, dtype=np.float32)).to(device),\n",
    "            torch.from_numpy(np.array(mini_batch_move, dtype=np.long)).to(device),\n",
    "            torch.from_numpy(np.array(mini_batch_win, dtype=np.float32).reshape((-1, 1))).to(device))\n",
    "    \n",
    "def accuracy(y, t):\n",
    "    return (torch.max(y, 1)[1] == t).sum().item() / len(t)\n",
    "\n",
    "def binary_accuracy(y, t):\n",
    "    pred = y >= 0\n",
    "    truth = t >= 0.5\n",
    "    return pred.eq(truth).sum().item() / len(t)\n",
    "\n",
    "def save_checkpoint():        \n",
    "    logging.info('save checkpoint')\n",
    "    path = f'{args.checkpoint}_{epoch}_{t}'\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        't': t,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初期設定（Resume Train / CSAファイルからFeaturesを抽出）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init/Resume\n",
    "if args.initmodel:\n",
    "    logging.info('Load model from {}'.format(args.initmodel))\n",
    "    serializers.load_npz(args.initmodel, model)\n",
    "if args.resume:\n",
    "    checkpoint = torch.load(args.resume, map_location=device)\n",
    "    logging.info(f'Loading the checkpoint from {args.resume}')\n",
    "    epoch = checkpoint['epoch']\n",
    "    t = checkpoint['t']\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "else:\n",
    "    epoch = 0\n",
    "    t = 0\n",
    "    \n",
    "logging.info('read kifu start')\n",
    "\n",
    "# 保存済みのpickleファイルがある場合、pickleファイルを読み込む\n",
    "# train date\n",
    "train_pickle_filename = re.sub(r'\\..*?$', '', args.kifulist_train) + '.pickle'\n",
    "\n",
    "if os.path.exists(train_pickle_filename):\n",
    "    with open(train_pickle_filename, 'rb') as f:\n",
    "        positions_train = pickle.load(f)\n",
    "    logging.info(train_pickle_filename)\n",
    "    logging.info('load train pickle')\n",
    "else:\n",
    "    positions_train = read_kifu(f'./data/{args.kifulist_train}')\n",
    "\n",
    "# test data\n",
    "test_pickle_filename = re.sub(r'\\..*?$', '', args.kifulist_test) + '.pickle'\n",
    "if os.path.exists(test_pickle_filename):\n",
    "    with open(test_pickle_filename, 'rb') as f:\n",
    "        positions_test = pickle.load(f)\n",
    "    logging.info('load test pickle')\n",
    "else:\n",
    "    positions_test = read_kifu(f'./data/{args.kifulist_test}')\n",
    "\n",
    "# 保存済みのpickleがない場合、pickleファイルを保存する\n",
    "if not os.path.exists(train_pickle_filename):\n",
    "    with open(train_pickle_filename, 'wb') as f:\n",
    "        pickle.dump(positions_train, f, pickle.HIGHEST_PROTOCOL)\n",
    "    logging.info('save train pickle')\n",
    "if not os.path.exists(test_pickle_filename):\n",
    "    with open(test_pickle_filename, 'wb') as f:\n",
    "        pickle.dump(positions_test, f, pickle.HIGHEST_PROTOCOL)\n",
    "    logging.info('save test pickle')\n",
    "logging.info('read kifu end')\n",
    "\n",
    "logging.info('train position num = {}'.format(len(positions_train)))\n",
    "logging.info('test position num = {}'.format(len(positions_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# train\n",
    "logging.info('start training')\n",
    "\n",
    "itr = 0\n",
    "sum_loss1 = 0\n",
    "sum_loss2 = 0\n",
    "sum_loss = 0\n",
    "\n",
    "for e in range(args.epoch):\n",
    "    epoch += 1\n",
    "    itr_eval = 0\n",
    "    sum_loss1_eval = 0\n",
    "    sum_loss2_eval = 0\n",
    "    sum_loss_eval = 0\n",
    "\n",
    "    positions_train_shuffled = random.sample(positions_train, len(positions_train))\n",
    "  \n",
    "    for i in range(0, len(positions_train_shuffled)-args.batchsize, args.batchsize):\n",
    "        t += 1\n",
    "        itr += 1\n",
    "        itr_eval += 1\n",
    "\n",
    "        x, t1, t2 = mini_batch(positions_train_shuffled, i, args.batchsize)\n",
    "        model.train()\n",
    "        x, t1, t2 = mini_batch(positions_train_shuffled, i, args.batchsize)\n",
    "        model.train()\n",
    "        y1, y2 = model(x)\n",
    "\n",
    "        loss1 = cross_entropy_loss(y1, t1)\n",
    "        loss1 = loss1.mean()\n",
    "        loss2 = bce_with_logits_loss(y2, t2)\n",
    "        loss = loss1 + loss2\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sum_loss1_eval += loss1.item()\n",
    "        sum_loss2_eval += loss2.item()\n",
    "        sum_loss_eval += loss.item()\n",
    "\n",
    "        sum_loss1 += loss1.item()\n",
    "        sum_loss2 += loss2.item()\n",
    "        sum_loss += loss.item()\n",
    "\n",
    "        if t % args.eval_interval == 0:\n",
    "            with torch.no_grad():\n",
    "                x, t1, t2 = mini_batch_for_test(positions_test, args.test_batchsize)\n",
    "                y1, y2 = model(x)\n",
    "\n",
    "                loss1 = cross_entropy_loss(y1, t1)\n",
    "                loss1 = loss1.mean()\n",
    "                loss2 = bce_with_logits_loss(y2, t2)\n",
    "                loss = loss1 + loss2\n",
    "\n",
    "                loss, current = loss1.item(), t\n",
    "                # print(f\"loss1: {loss1:>7f}  loss2: {loss2:>7f}  loss: {loss:>7f}  [{current:>5d}]\")\n",
    "                logging.info('epoch = {}, iteration = {}, loss_policy = {}, loss_value = {}, loss = {}, accuracy = {}, {}'.format(\n",
    "                    epoch, t, sum_loss1/itr, sum_loss2/itr, sum_loss/itr ,accuracy(y1,t1), binary_accuracy(y2,t2)))\n",
    "\n",
    "                itr = 0\n",
    "                sum_loss1 = 0\n",
    "                sum_loss2 = 0\n",
    "                sum_loss = 0\n",
    "          \n",
    "    logging.info('validate test set')\n",
    "    itr_test = 0\n",
    "    sum_test_accuracy1 = 0\n",
    "    sum_test_accuracy2 = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(positions_test)-args.batchsize, args.batchsize):\n",
    "            x, t1, t2 = mini_batch_for_test(positions_test, args.batchsize)\n",
    "            y1 = model(x)\n",
    "\n",
    "            itr_test += 1\n",
    "            sum_test_accuracy1 += accuracy(y1, t1)\n",
    "            sum_test_accuracy2 += binary_accuracy(y2, t2)\n",
    "\n",
    "        logging.info('epoch = {}, iteration = {}, loss_polish = {}, loss_value = {}, loss = {}, accuracy = {}, {}'.format(\n",
    "            epoch, t, sum_loss1_eval/itr_eval, sum_loss2_eval/itr_eval, sum_loss_eval/itr_eval, sum_test_accuracy1/itr_test, sum_test_accuracy2/itr_test))\n",
    "\n",
    "        writer.add_scalar('Train_Loss_Policy/Iteration', sum_loss1_eval/itr_eval, t)\n",
    "        writer.add_scalar('Train_Loss_Value/Iteration', sum_loss2_eval/itr_eval, t)\n",
    "        writer.add_scalar('Train_Loss/Iteration', sum_loss_eval/itr_eval, t)\n",
    "\n",
    "        writer.add_scalar('Test_Acc_Policy/Iteration', sum_test_accuracy1/itr_test, t)\n",
    "        writer.add_scalar('Test_Acc_/Iteration', sum_test_accuracy2/itr_test, t)\n",
    "\n",
    "    if e % args.save_interval_epoch == 0:\n",
    "        save_checkpoint()\n",
    "\n",
    "logging.info('End train')\n",
    "save_checkpoint()\n",
    "\n",
    "logging.info('Save model : {}'.format(args.model))\n",
    "serializers.save_npz(args.model, model)\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('nhandsome_vscode': conda)",
   "language": "python",
   "name": "python37464bitnhandsomevscodeconda77d3a77a3efc4a4db975e8cab8804a1b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
