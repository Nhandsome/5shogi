{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/han/python-shogi\n",
      "Installing collected packages: python-shogi\n",
      "  Attempting uninstall: python-shogi\n",
      "    Found existing installation: python-shogi 1.0.14\n",
      "    Uninstalling python-shogi-1.0.14:\n",
      "      Successfully uninstalled python-shogi-1.0.14\n",
      "  Running setup.py develop for python-shogi\n",
      "Successfully installed python-shogi-1.0.14\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-cache-dir -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/csa_train/.DS_Store\n",
      "./data/csa_train/test_2025.csa\n",
      "./data/csa_train/test_1279.csa\n",
      "./data/csa_train/test_1041.csa\n",
      "./data/csa_train/test.csa\n",
      "kifu count : 2022\n"
     ]
    }
   ],
   "source": [
    "! python utils/filter_csa.py --dir ./data/csa_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total kifu num = 2023\r\n",
      "train kifu num = 1820\r\n",
      "test kifu num = 203\r\n"
     ]
    }
   ],
   "source": [
    "!python utils/make_kifu_list.py ./data/csa_train './data/kifu_list_random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from shogi.common import *\n",
    "from shogi.features import *\n",
    "from shogi.read_kifu import *\n",
    "from shogi.network.policyvalue_res import PolicyValueResNetwork\n",
    "from shogi.network.policy import PolicyNetwork\n",
    "from shogi import serializers\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/09/14 02:38:45\tINFO\tcheckpoint : checkpoint/5_test_210913_1\n",
      "2021/09/14 02:38:45\tINFO\tbatchsize : 32\n",
      "2021/09/14 02:38:45\tINFO\tinitmodel : \n",
      "2021/09/14 02:38:45\tINFO\tresume : \n",
      "2021/09/14 02:38:45\tINFO\tlog : None\n",
      "2021/09/14 02:38:45\tINFO\tlr : 0.01\n"
     ]
    }
   ],
   "source": [
    "# setting\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('kifulist_train', type=str)\n",
    "parser.add_argument('kifulist_test', type=str)\n",
    "parser.add_argument('--batchsize', '-b', type=int, default=32)\n",
    "parser.add_argument('--test_batchsize', type=int, default=512)\n",
    "parser.add_argument('--epoch', '-e', type=int, default=1)\n",
    "parser.add_argument('--model', type=str, default='model/model_test')\n",
    "parser.add_argument('--state', type=str, default='model/state_test')\n",
    "parser.add_argument('--checkpoint', type=str, default='')\n",
    "parser.add_argument('--initmodel', '-m', type=str, default='')\n",
    "parser.add_argument('--resume', '-r', type=str, default='')\n",
    "parser.add_argument('--log', default=None)\n",
    "parser.add_argument('--lr', type=float, default=0.01)\n",
    "parser.add_argument('--eval_interval', '-i', type=int, default=1000)\n",
    "parser.add_argument('--save_interval_epoch', type=int, default=10)\n",
    "\n",
    "# '--resume', 'checkpoint/210910_15_837419',\n",
    "args = parser.parse_args(args=['kifu_list_train.txt', 'kifu_list_test.txt', '--epoch', '3', '--model', 'model/5_test_210913_1', '--checkpoint', 'checkpoint/5_test_210913_1', '--eval_interval', '2',  '--save_interval_epoch', '5'])\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "# device = 'cpu'\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s\\t%(levelname)s\\t%(message)s', datefmt='%Y/%m/%d %H:%M:%S', filename=args.log, level=logging.DEBUG)\n",
    "logging.info('checkpoint : {}'.format(args.checkpoint))\n",
    "logging.info('batchsize : {}'.format(args.batchsize))\n",
    "logging.info('initmodel : {}'.format(args.initmodel))\n",
    "logging.info('resume : {}'.format(args.resume))\n",
    "logging.info('log : {}'.format(args.log))\n",
    "logging.info('lr : {}'.format(args.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "num_resnet = 3\n",
    "num_channel = 80\n",
    "\n",
    "model=PolicyValueResNetwork(num_resnet, num_channel)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(),lr=args.lr)\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "bce_with_logits_loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neede functions\n",
    "def mini_batch(positions, i, batchsize):\n",
    "    mini_batch_data = []\n",
    "    mini_batch_move = []\n",
    "    mini_batch_win = []\n",
    "    for b in range(batchsize):\n",
    "        features, move, win = make_features(positions[i + b])\n",
    "        mini_batch_data.append(features)\n",
    "        mini_batch_move.append(move)\n",
    "        mini_batch_win.append(win)\n",
    "\n",
    "    return (torch.from_numpy(np.array(mini_batch_data, dtype=np.float32)).to(device),\n",
    "            torch.from_numpy(np.array(mini_batch_move, dtype=np.long)).to(device),\n",
    "            torch.from_numpy(np.array(mini_batch_win, dtype=np.float32).reshape((-1, 1))).to(device))\n",
    "\n",
    "def mini_batch_for_test(positions, batchsize):\n",
    "    mini_batch_data = []\n",
    "    mini_batch_move = []\n",
    "    mini_batch_win = []\n",
    "    for b in range(batchsize):\n",
    "        features, move, win = make_features(random.choice(positions))\n",
    "        mini_batch_data.append(features)\n",
    "        mini_batch_move.append(move)\n",
    "        mini_batch_win.append(win)\n",
    "\n",
    "    return (torch.from_numpy(np.array(mini_batch_data, dtype=np.float32)).to(device),\n",
    "            torch.from_numpy(np.array(mini_batch_move, dtype=np.long)).to(device),\n",
    "            torch.from_numpy(np.array(mini_batch_win, dtype=np.float32).reshape((-1, 1))).to(device))\n",
    "    \n",
    "def accuracy(y, t):\n",
    "    return (torch.max(y, 1)[1] == t).sum().item() / len(t)\n",
    "\n",
    "def binary_accuracy(y, t):\n",
    "    pred = y >= 0\n",
    "    truth = t >= 0.5\n",
    "    return pred.eq(truth).sum().item() / len(t)\n",
    "\n",
    "def save_checkpoint():        \n",
    "    logging.info('save checkpoint')\n",
    "    path = f'{args.checkpoint}_{epoch}_{t}'\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        't': t,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/09/14 02:38:50\tINFO\tread kifu start\n",
      "2021/09/14 02:38:51\tINFO\tkifu_list_train.pickle\n",
      "2021/09/14 02:38:51\tINFO\tload train pickle\n",
      "2021/09/14 02:38:51\tINFO\tload test pickle\n",
      "2021/09/14 02:38:51\tINFO\tread kifu end\n",
      "2021/09/14 02:38:51\tINFO\ttrain position num = 3313\n",
      "2021/09/14 02:38:51\tINFO\ttest position num = 471\n"
     ]
    }
   ],
   "source": [
    "# Init/Resume\n",
    "if args.initmodel:\n",
    "    logging.info('Load model from {}'.format(args.initmodel))\n",
    "    serializers.load_npz(args.initmodel, model)\n",
    "if args.resume:\n",
    "    checkpoint = torch.load(args.resume, map_location=device)\n",
    "    logging.info(f'Loading the checkpoint from {args.resume}')\n",
    "    epoch = checkpoint['epoch']\n",
    "    t = checkpoint['t']\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "else:\n",
    "    epoch = 0\n",
    "    t = 0\n",
    "    \n",
    "logging.info('read kifu start')\n",
    "\n",
    "# 保存済みのpickleファイルがある場合、pickleファイルを読み込む\n",
    "# train date\n",
    "train_pickle_filename = re.sub(r'\\..*?$', '', args.kifulist_train) + '.pickle'\n",
    "\n",
    "if os.path.exists(train_pickle_filename):\n",
    "    with open(train_pickle_filename, 'rb') as f:\n",
    "        positions_train = pickle.load(f)\n",
    "    logging.info(train_pickle_filename)\n",
    "    logging.info('load train pickle')\n",
    "else:\n",
    "    positions_train = read_kifu(f'./data/{args.kifulist_train}')\n",
    "\n",
    "# test data\n",
    "test_pickle_filename = re.sub(r'\\..*?$', '', args.kifulist_test) + '.pickle'\n",
    "if os.path.exists(test_pickle_filename):\n",
    "    with open(test_pickle_filename, 'rb') as f:\n",
    "        positions_test = pickle.load(f)\n",
    "    logging.info('load test pickle')\n",
    "else:\n",
    "    positions_test = read_kifu(f'./data/{args.kifulist_test}')\n",
    "\n",
    "# 保存済みのpickleがない場合、pickleファイルを保存する\n",
    "if not os.path.exists(train_pickle_filename):\n",
    "    with open(train_pickle_filename, 'wb') as f:\n",
    "        pickle.dump(positions_train, f, pickle.HIGHEST_PROTOCOL)\n",
    "    logging.info('save train pickle')\n",
    "if not os.path.exists(test_pickle_filename):\n",
    "    with open(test_pickle_filename, 'wb') as f:\n",
    "        pickle.dump(positions_test, f, pickle.HIGHEST_PROTOCOL)\n",
    "    logging.info('save test pickle')\n",
    "logging.info('read kifu end')\n",
    "\n",
    "logging.info('train position num = {}'.format(len(positions_train)))\n",
    "logging.info('test position num = {}'.format(len(positions_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/09/14 02:43:28\tINFO\tstart training\n",
      "2021/09/14 02:43:29\tINFO\tepoch = 2, iteration = 4, loss_policy = 6.467972993850708, loss_value = 0.6889800131320953, loss = 7.1569530963897705, accuracy = 0.0078125, 0.509765625\n",
      "2021/09/14 02:43:30\tINFO\tepoch = 2, iteration = 6, loss_policy = 6.3110997676849365, loss_value = 0.6866650581359863, loss = 6.997764825820923, accuracy = 0.017578125, 0.521484375\n",
      "2021/09/14 02:43:31\tINFO\tepoch = 2, iteration = 8, loss_policy = 5.906799077987671, loss_value = 0.6855629682540894, loss = 6.592361927032471, accuracy = 0.044921875, 0.5390625\n",
      "2021/09/14 02:43:31\tINFO\tepoch = 2, iteration = 10, loss_policy = 5.728514909744263, loss_value = 0.6945554316043854, loss = 6.423070192337036, accuracy = 0.07421875, 0.515625\n",
      "2021/09/14 02:43:32\tINFO\tepoch = 2, iteration = 12, loss_policy = 5.382267236709595, loss_value = 0.6812370419502258, loss = 6.063504457473755, accuracy = 0.0703125, 0.521484375\n",
      "2021/09/14 02:43:33\tINFO\tepoch = 2, iteration = 14, loss_policy = 5.554412841796875, loss_value = 0.6785607635974884, loss = 6.232973575592041, accuracy = 0.0625, 0.5234375\n",
      "2021/09/14 02:43:33\tINFO\tepoch = 2, iteration = 16, loss_policy = 5.565819263458252, loss_value = 0.6998418271541595, loss = 6.265661239624023, accuracy = 0.0703125, 0.529296875\n",
      "2021/09/14 02:43:34\tINFO\tepoch = 2, iteration = 18, loss_policy = 5.42069935798645, loss_value = 0.6777488589286804, loss = 6.098448276519775, accuracy = 0.072265625, 0.513671875\n",
      "2021/09/14 02:43:35\tINFO\tepoch = 2, iteration = 20, loss_policy = 4.945746898651123, loss_value = 0.696975827217102, loss = 5.642722845077515, accuracy = 0.09765625, 0.505859375\n",
      "2021/09/14 02:43:35\tINFO\tepoch = 2, iteration = 22, loss_policy = 5.103555917739868, loss_value = 0.6923344433307648, loss = 5.7958903312683105, accuracy = 0.09765625, 0.560546875\n",
      "2021/09/14 02:43:36\tINFO\tepoch = 2, iteration = 24, loss_policy = 4.974485874176025, loss_value = 0.6922540366649628, loss = 5.6667399406433105, accuracy = 0.09375, 0.517578125\n",
      "2021/09/14 02:43:36\tINFO\tepoch = 2, iteration = 26, loss_policy = 4.990840911865234, loss_value = 0.6865178346633911, loss = 5.677358865737915, accuracy = 0.09375, 0.509765625\n",
      "2021/09/14 02:43:37\tINFO\tepoch = 2, iteration = 28, loss_policy = 4.890884637832642, loss_value = 0.7028066217899323, loss = 5.593691110610962, accuracy = 0.10546875, 0.5\n",
      "2021/09/14 02:43:38\tINFO\tepoch = 2, iteration = 30, loss_policy = 4.842865228652954, loss_value = 0.7001003324985504, loss = 5.542965412139893, accuracy = 0.140625, 0.541015625\n",
      "2021/09/14 02:43:38\tINFO\tepoch = 2, iteration = 32, loss_policy = 4.2893465757369995, loss_value = 0.6960569024085999, loss = 4.985403299331665, accuracy = 0.09375, 0.51171875\n",
      "2021/09/14 02:43:39\tINFO\tepoch = 2, iteration = 34, loss_policy = 4.603617906570435, loss_value = 0.6952351033687592, loss = 5.298853158950806, accuracy = 0.125, 0.5390625\n",
      "2021/09/14 02:43:40\tINFO\tepoch = 2, iteration = 36, loss_policy = 4.997539043426514, loss_value = 0.7024614810943604, loss = 5.700000524520874, accuracy = 0.1015625, 0.51171875\n",
      "2021/09/14 02:43:40\tINFO\tepoch = 2, iteration = 38, loss_policy = 4.814639329910278, loss_value = 0.6890389919281006, loss = 5.503678321838379, accuracy = 0.12890625, 0.51953125\n",
      "2021/09/14 02:43:41\tINFO\tepoch = 2, iteration = 40, loss_policy = 4.560570240020752, loss_value = 0.677531898021698, loss = 5.238102197647095, accuracy = 0.1015625, 0.517578125\n",
      "2021/09/14 02:43:41\tINFO\tepoch = 2, iteration = 42, loss_policy = 4.541142463684082, loss_value = 0.7233551442623138, loss = 5.264497518539429, accuracy = 0.16796875, 0.4921875\n",
      "2021/09/14 02:43:42\tINFO\tepoch = 2, iteration = 44, loss_policy = 4.660008907318115, loss_value = 0.6862248778343201, loss = 5.34623384475708, accuracy = 0.1484375, 0.51953125\n",
      "2021/09/14 02:43:43\tINFO\tepoch = 2, iteration = 46, loss_policy = 4.852561950683594, loss_value = 0.6938062012195587, loss = 5.54636812210083, accuracy = 0.138671875, 0.54296875\n",
      "2021/09/14 02:43:44\tINFO\tepoch = 2, iteration = 48, loss_policy = 4.387333869934082, loss_value = 0.6884675920009613, loss = 5.075801610946655, accuracy = 0.126953125, 0.49609375\n",
      "2021/09/14 02:43:44\tINFO\tepoch = 2, iteration = 50, loss_policy = 4.429281234741211, loss_value = 0.7019260823726654, loss = 5.131207466125488, accuracy = 0.1640625, 0.5\n",
      "2021/09/14 02:43:45\tINFO\tepoch = 2, iteration = 52, loss_policy = 4.450685977935791, loss_value = 0.6998834311962128, loss = 5.150569438934326, accuracy = 0.1328125, 0.484375\n",
      "2021/09/14 02:43:45\tINFO\tepoch = 2, iteration = 54, loss_policy = 4.328619360923767, loss_value = 0.6989416778087616, loss = 5.027561187744141, accuracy = 0.162109375, 0.5234375\n",
      "2021/09/14 02:43:46\tINFO\tepoch = 2, iteration = 56, loss_policy = 4.289312124252319, loss_value = 0.6816363632678986, loss = 4.970948696136475, accuracy = 0.150390625, 0.529296875\n",
      "2021/09/14 02:43:47\tINFO\tepoch = 2, iteration = 58, loss_policy = 4.027209639549255, loss_value = 0.703768253326416, loss = 4.730978012084961, accuracy = 0.1796875, 0.5\n",
      "2021/09/14 02:43:47\tINFO\tepoch = 2, iteration = 60, loss_policy = 4.568254709243774, loss_value = 0.6918237805366516, loss = 5.260078430175781, accuracy = 0.1875, 0.486328125\n",
      "2021/09/14 02:43:48\tINFO\tepoch = 2, iteration = 62, loss_policy = 4.450041770935059, loss_value = 0.7034087479114532, loss = 5.1534504890441895, accuracy = 0.185546875, 0.5078125\n",
      "2021/09/14 02:43:49\tINFO\tepoch = 2, iteration = 64, loss_policy = 4.206924915313721, loss_value = 0.6864960193634033, loss = 4.893421173095703, accuracy = 0.189453125, 0.5\n",
      "2021/09/14 02:43:49\tINFO\tepoch = 2, iteration = 66, loss_policy = 4.344672679901123, loss_value = 0.689801812171936, loss = 5.034474611282349, accuracy = 0.154296875, 0.50390625\n",
      "2021/09/14 02:43:50\tINFO\tepoch = 2, iteration = 68, loss_policy = 4.0299859046936035, loss_value = 0.6799221336841583, loss = 4.7099080085754395, accuracy = 0.15234375, 0.521484375\n",
      "2021/09/14 02:43:51\tINFO\tepoch = 2, iteration = 70, loss_policy = 3.927754044532776, loss_value = 0.679106205701828, loss = 4.606860160827637, accuracy = 0.166015625, 0.50390625\n",
      "2021/09/14 02:43:51\tINFO\tepoch = 2, iteration = 72, loss_policy = 3.855384945869446, loss_value = 0.696168839931488, loss = 4.551553726196289, accuracy = 0.21484375, 0.51953125\n",
      "2021/09/14 02:43:52\tINFO\tepoch = 2, iteration = 74, loss_policy = 4.24640679359436, loss_value = 0.7007339000701904, loss = 4.947140693664551, accuracy = 0.169921875, 0.474609375\n",
      "2021/09/14 02:43:53\tINFO\tepoch = 2, iteration = 76, loss_policy = 4.274076223373413, loss_value = 0.6769641637802124, loss = 4.951040267944336, accuracy = 0.2109375, 0.54296875\n",
      "2021/09/14 02:43:54\tINFO\tepoch = 2, iteration = 78, loss_policy = 4.099067211151123, loss_value = 0.6736884117126465, loss = 4.7727556228637695, accuracy = 0.158203125, 0.50390625\n",
      "2021/09/14 02:43:55\tINFO\tepoch = 2, iteration = 80, loss_policy = 3.8484816551208496, loss_value = 0.68979811668396, loss = 4.53827977180481, accuracy = 0.181640625, 0.49609375\n",
      "2021/09/14 02:43:55\tINFO\tepoch = 2, iteration = 82, loss_policy = 4.326521635055542, loss_value = 0.6912150382995605, loss = 5.0177366733551025, accuracy = 0.181640625, 0.515625\n",
      "2021/09/14 02:43:56\tINFO\tepoch = 2, iteration = 84, loss_policy = 3.7593947649002075, loss_value = 0.7066673338413239, loss = 4.466062068939209, accuracy = 0.171875, 0.5625\n",
      "2021/09/14 02:43:57\tINFO\tepoch = 2, iteration = 86, loss_policy = 4.362645983695984, loss_value = 0.6979073286056519, loss = 5.060553550720215, accuracy = 0.138671875, 0.50390625\n",
      "2021/09/14 02:43:58\tINFO\tepoch = 2, iteration = 88, loss_policy = 3.5232831239700317, loss_value = 0.6902229189872742, loss = 4.213506102561951, accuracy = 0.21484375, 0.501953125\n",
      "2021/09/14 02:43:58\tINFO\tepoch = 2, iteration = 90, loss_policy = 3.3400319814682007, loss_value = 0.7017084062099457, loss = 4.041740298271179, accuracy = 0.193359375, 0.498046875\n",
      "2021/09/14 02:43:59\tINFO\tepoch = 2, iteration = 92, loss_policy = 4.310548305511475, loss_value = 0.6927042901515961, loss = 5.0032525062561035, accuracy = 0.2109375, 0.53125\n",
      "2021/09/14 02:44:00\tINFO\tepoch = 2, iteration = 94, loss_policy = 4.029633522033691, loss_value = 0.6970174312591553, loss = 4.726650953292847, accuracy = 0.203125, 0.5078125\n",
      "2021/09/14 02:44:01\tINFO\tepoch = 2, iteration = 96, loss_policy = 3.8901355266571045, loss_value = 0.6932186782360077, loss = 4.583354234695435, accuracy = 0.189453125, 0.533203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/09/14 02:44:01\tINFO\tepoch = 2, iteration = 98, loss_policy = 4.131300926208496, loss_value = 0.6905283331871033, loss = 4.821829319000244, accuracy = 0.19140625, 0.5546875\n",
      "2021/09/14 02:44:02\tINFO\tepoch = 2, iteration = 100, loss_policy = 4.014870762825012, loss_value = 0.6783401072025299, loss = 4.69321084022522, accuracy = 0.201171875, 0.5234375\n",
      "2021/09/14 02:44:03\tINFO\tepoch = 2, iteration = 102, loss_policy = 4.14655613899231, loss_value = 0.7063133716583252, loss = 4.852869510650635, accuracy = 0.203125, 0.52734375\n",
      "2021/09/14 02:44:03\tINFO\tepoch = 2, iteration = 104, loss_policy = 3.679903268814087, loss_value = 0.6984361410140991, loss = 4.378339529037476, accuracy = 0.21484375, 0.521484375\n",
      "2021/09/14 02:44:03\tINFO\tvalidate test set\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "max() received an invalid combination of arguments - got (tuple, int), but expected one of:\n * (Tensor input)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e88830221756>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mitr_test\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0msum_test_accuracy1\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0msum_test_accuracy2\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-1419f2657400>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(y, t)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: max() received an invalid combination of arguments - got (tuple, int), but expected one of:\n * (Tensor input)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# train\n",
    "logging.info('start training')\n",
    "\n",
    "itr = 0\n",
    "sum_loss1 = 0\n",
    "sum_loss2 = 0\n",
    "sum_loss = 0\n",
    "\n",
    "for e in range(args.epoch):\n",
    "    epoch += 1\n",
    "    itr_eval = 0\n",
    "    sum_loss1_eval = 0\n",
    "    sum_loss2_eval = 0\n",
    "    sum_loss_eval = 0\n",
    "\n",
    "    positions_train_shuffled = random.sample(positions_train, len(positions_train))\n",
    "  \n",
    "    for i in range(0, len(positions_train_shuffled)-args.batchsize, args.batchsize):\n",
    "        t += 1\n",
    "        itr += 1\n",
    "        itr_eval += 1\n",
    "\n",
    "        x, t1, t2 = mini_batch(positions_train_shuffled, i, args.batchsize)\n",
    "        model.train()\n",
    "        x, t1, t2 = mini_batch(positions_train_shuffled, i, args.batchsize)\n",
    "        model.train()\n",
    "        y1, y2 = model(x)\n",
    "\n",
    "        loss1 = cross_entropy_loss(y1, t1)\n",
    "        loss1 = loss1.mean()\n",
    "        loss2 = bce_with_logits_loss(y2, t2)\n",
    "        loss = loss1 + loss2\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sum_loss1_eval += loss1.item()\n",
    "        sum_loss2_eval += loss2.item()\n",
    "        sum_loss_eval += loss.item()\n",
    "\n",
    "        sum_loss1 += loss1.item()\n",
    "        sum_loss2 += loss2.item()\n",
    "        sum_loss += loss.item()\n",
    "\n",
    "        if t % args.eval_interval == 0:\n",
    "            with torch.no_grad():\n",
    "                x, t1, t2 = mini_batch_for_test(positions_test, args.test_batchsize)\n",
    "                y1, y2 = model(x)\n",
    "\n",
    "                loss1 = cross_entropy_loss(y1, t1)\n",
    "                loss1 = loss1.mean()\n",
    "                loss2 = bce_with_logits_loss(y2, t2)\n",
    "                loss = loss1 + loss2\n",
    "\n",
    "                loss, current = loss1.item(), t\n",
    "                # print(f\"loss1: {loss1:>7f}  loss2: {loss2:>7f}  loss: {loss:>7f}  [{current:>5d}]\")\n",
    "                logging.info('epoch = {}, iteration = {}, loss_policy = {}, loss_value = {}, loss = {}, accuracy = {}, {}'.format(\n",
    "                    epoch, t, sum_loss1/itr, sum_loss2/itr, sum_loss/itr ,accuracy(y1,t1), binary_accuracy(y2,t2)))\n",
    "\n",
    "                itr = 0\n",
    "                sum_loss1 = 0\n",
    "                sum_loss2 = 0\n",
    "                sum_loss = 0\n",
    "          \n",
    "    logging.info('validate test set')\n",
    "    itr_test = 0\n",
    "    sum_test_accuracy1 = 0\n",
    "    sum_test_accuracy2 = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(positions_test)-args.batchsize, args.batchsize):\n",
    "            x, t1, t2 = mini_batch_for_test(positions_test, args.batchsize)\n",
    "            y1 = model(x)\n",
    "\n",
    "            itr_test += 1\n",
    "            sum_test_accuracy1 += accuracy(y1, t1)\n",
    "            sum_test_accuracy2 += binary_accuracy(y2, t2)\n",
    "\n",
    "        logging.info('epoch = {}, iteration = {}, loss_polish = {}, loss_value = {}, loss = {}, accuracy = {}, {}'.format(\n",
    "            epoch, t, sum_loss1_eval/itr_eval, sum_loss2_eval/itr_eval, sum_loss_eval/itr_eval, sum_test_accuracy1/itr_test, sum_test_accuracy2/itr_test))\n",
    "\n",
    "        writer.add_scalar('Train_Loss_Policy/Iteration', sum_loss1_eval/itr_eval, t)\n",
    "        writer.add_scalar('Train_Loss_Value/Iteration', sum_loss2_eval/itr_eval, t)\n",
    "        writer.add_scalar('Train_Loss/Iteration', sum_loss_eval/itr_eval, t)\n",
    "\n",
    "        writer.add_scalar('Test_Acc_Policy/Iteration', sum_test_accuracy1/itr_test, t)\n",
    "        writer.add_scalar('Test_Acc_/Iteration', sum_test_accuracy2/itr_test, t)\n",
    "\n",
    "    if e % args.save_interval_epoch == 0:\n",
    "        save_checkpoint()\n",
    "\n",
    "logging.info('End train')\n",
    "save_checkpoint()\n",
    "\n",
    "logging.info('Save model : {}'.format(args.model))\n",
    "serializers.save_npz(args.model, model)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/09/13 20:06:09\tINFO\tSave model : model/5_shogi_210913_1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('nhandsome_vscode': conda)",
   "language": "python",
   "name": "python37464bitnhandsomevscodeconda77d3a77a3efc4a4db975e8cab8804a1b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
